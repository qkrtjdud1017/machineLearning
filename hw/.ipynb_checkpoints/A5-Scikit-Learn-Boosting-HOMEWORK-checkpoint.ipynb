{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Boosting\n",
    "\n",
    "### <span style=\"color:red\">THIS IS HOMEWORK.</span>\n",
    "### Due: May 15th, 11:59 pm on Canvas.\n",
    "> **Copyright Â©2019 University of Washington**  \n",
    "\n",
    "> **Emily Fox**, author of the TuriCreate based version of this assignment.  \n",
    "> **Sewoong Oh**, instructor of CSE/STAT 416 for Spring 2019.  \n",
    "> **Joshua Fan**, generously offered a LOT help in debugging and testing.\n",
    "> **Anna Neufeld**, generously offered a lot of help in code review. \n",
    "> **Hongjun Wu**, revisor of the Scikit-Learn based version of this assignment.  \n",
    "> **Henry Wong**, wrote the pre-processing code for categorical encoding.    \n",
    "> **All rights reserved.**\n",
    "\n",
    "### Clarification\n",
    "* <span style=\"color:red\">Read & post to this [Assignment 5 Clarifications](https://canvas.uw.edu/courses/1271722/discussion_topics/4817620) if you are not sure of something.</span>\n",
    "\n",
    "### Purpose\n",
    "* We will explore the use of boosting. \n",
    "* We will play with the pre-implemented gradient boosted trees. \n",
    " \n",
    "### Method & Summary\n",
    "* Use Scikit-Learn to do some feature engineering.\n",
    "* Train a boosted ensemble of decision-trees (gradient boosted trees) on the LendingClub dataset.\n",
    "* Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "* Evaluate the trained model and compare it with a baseline.\n",
    "* Find the most positive and negative loans using the learned model.\n",
    "* Explore how the number of trees influences classification performance.\n",
    "\n",
    "### Permission\n",
    "* Permission is hereby granted to students registered for University of Washington CSE/STAT 416.\n",
    "* For use solely during Spring Quarter 2019 for purposes of the course.  \n",
    "* No other use, copying, distribution, or modification is permitted without prior written consent. \n",
    "* Copyrights for third-party components of this work must be honored.  \n",
    "* Instructors interested in reusing these course materials should contact the author.\n",
    "\n",
    "> If you have any questions or you are unclear what we are refering to in this homework, please do not hesitate to reach out! Post a discussion and we would love to listen to and answer your questions. Hope you enjoy this assignment ðŸ˜œ (Well I enjoyed writing it since ya don't get the chance to write emoji into CSE assignment prompt at 4AM very often)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statement\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic Function (Like...magic)\n",
    "# Interested? Don't know what it means? Read this!\n",
    "# https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Make Pandas print more stuff\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, stuff wrote in blockquotes is optional. Just something we think is useful to have around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LendingClub dataset\n",
    "\n",
    "We will be using the [LendingClub](https://www.lendingclub.com/) data. \n",
    "* The [LendingClub](https://www.lendingclub.com/) is a peer-to-peer leading company that directly connects borrowers and potential lenders/investors.\n",
    "\n",
    "Just like we did in previous assignments, we will build a classification model to predict whether or not a loan provided by lending club is likely to default.\n",
    "\n",
    "In the decision trees assignment, we walked through several steps of data preparation, for example:\n",
    "- converting the target column to [-1, +1]\n",
    "- selecting a subset of the features that we think will be important\n",
    "- skipping observations with missing values\n",
    "- sampling to balance the target classes\n",
    "\n",
    "To save time in this assignment, we have done these steps in advance, and saved the `DataFrame` in a new file called `clean-lending-club-data.csv`, which we can load in and immediately work with. If you are interested in these data preparation steps, please refer back to A4.\n",
    "\n",
    "### Load Data Basics\n",
    "* First, we will load in all the club data from file using `pd.read_csv()`. \n",
    "\n",
    "> If you need the dataset:   \n",
    "Download it in Canvas under [/files/Assignment Resources/data/](https://canvas.uw.edu/courses/1271722/files/folder/Assignment%20Resources/data).  \n",
    "\n",
    "> If data failed to load:   \n",
    "[1] Check if you have the correct file and is in the correct location!   \n",
    "[2] Make sure you have `clean-lending-club-data.csv`, not `clean-lending-club-data.gl`!\n",
    "\n",
    "> Reminders:  \n",
    "`'./'` means that you are finding a file within the same directory as the notebook.   \n",
    "`'../'` means that you are looking for a file or folder one hierarchy above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data = pd.read_csv('/data/clean-lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly explore what the dataset looks like.   \n",
    "First, let's print out the data and take a look at the column names to see what features we have in this dataset.   \n",
    "We talked about it since Assignment 2, so we won't belabor this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>dti</th>\n",
       "      <th>purpose</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>car</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>435.17</td>\n",
       "      <td>30000</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>59.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.55</td>\n",
       "      <td>small_business</td>\n",
       "      <td>4.57170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>294.94</td>\n",
       "      <td>40000</td>\n",
       "      <td>5600</td>\n",
       "      <td>5600</td>\n",
       "      <td>152.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>18.08</td>\n",
       "      <td>other</td>\n",
       "      <td>9.71600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>533.42</td>\n",
       "      <td>15000</td>\n",
       "      <td>5375</td>\n",
       "      <td>5350</td>\n",
       "      <td>121.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10.08</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>12.21520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>570.26</td>\n",
       "      <td>30000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>305.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>B</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>RENT</td>\n",
       "      <td>7.06</td>\n",
       "      <td>other</td>\n",
       "      <td>3.90888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>1393.42</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>325.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   safe_loans grade  sub_grade_num  short_emp  emp_length_num home_ownership    dti             purpose  payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  last_major_derog_none  open_acc  pub_rec  pub_rec_zero  revol_util  total_rec_late_fee  int_rate  total_rec_int  annual_inc  funded_amnt  funded_amnt_inv  installment\n",
       "0          -1     C            0.8          1               1           RENT   1.00                 car            2.39320            0                 1               5                 1                      1         3        0             1         9.4                 0.0     15.27         435.17       30000         2500             2500        59.83\n",
       "1          -1     F            0.4          0               5            OWN   5.55      small_business            4.57170            0                 1               2                 1                      1        11        0             1        32.6                 0.0     21.28         294.94       40000         5600             5600       152.39\n",
       "2          -1     B            1.0          1               1           RENT  18.08               other            9.71600            0                 1               0                 1                      1         2        0             1        36.5                 0.0     12.69         533.42       15000         5375             5350       121.45\n",
       "3          -1     C            0.2          1               1           RENT  10.08  debt_consolidation           12.21520            0                 1               1                 1                      1         4        0             1        91.7                 0.0     13.49         570.26       30000         9000             9000       305.38\n",
       "4          -1     B            0.4          0               4           RENT   7.06               other            3.90888            0                 1               2                 1                      1        14        0             1        55.5                 0.0     10.65        1393.42      100000        10000            10000       325.74"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and target\n",
    "> * The steps we did here to process data seems redundant...why don't we just call `pd.get_dummies(loans_data)`?\n",
    "    * You are right! Since we are moving to one-hot encoding categorical features, it is unnecessary to define the features first hand.\n",
    "    * However, the original version of this assignment had a detailed explaination of what each feature means.\n",
    "    * So if you are interested, you can see what all the features means below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>dti</th>\n",
       "      <th>purpose</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>safe_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>car</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>435.17</td>\n",
       "      <td>30000</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>59.83</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.55</td>\n",
       "      <td>small_business</td>\n",
       "      <td>4.57170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>294.94</td>\n",
       "      <td>40000</td>\n",
       "      <td>5600</td>\n",
       "      <td>5600</td>\n",
       "      <td>152.39</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>18.08</td>\n",
       "      <td>other</td>\n",
       "      <td>9.71600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>533.42</td>\n",
       "      <td>15000</td>\n",
       "      <td>5375</td>\n",
       "      <td>5350</td>\n",
       "      <td>121.45</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10.08</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>12.21520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>570.26</td>\n",
       "      <td>30000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>305.38</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>RENT</td>\n",
       "      <td>7.06</td>\n",
       "      <td>other</td>\n",
       "      <td>3.90888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>1393.42</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>325.74</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grade  sub_grade_num  short_emp  emp_length_num home_ownership    dti             purpose  payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  last_major_derog_none  open_acc  pub_rec  pub_rec_zero  revol_util  total_rec_late_fee  int_rate  total_rec_int  annual_inc  funded_amnt  funded_amnt_inv  installment  safe_loans\n",
       "0     C            0.8          1               1           RENT   1.00                 car            2.39320            0                 1               5                 1                      1         3        0             1         9.4                 0.0     15.27         435.17       30000         2500             2500        59.83          -1\n",
       "1     F            0.4          0               5            OWN   5.55      small_business            4.57170            0                 1               2                 1                      1        11        0             1        32.6                 0.0     21.28         294.94       40000         5600             5600       152.39          -1\n",
       "2     B            1.0          1               1           RENT  18.08               other            9.71600            0                 1               0                 1                      1         2        0             1        36.5                 0.0     12.69         533.42       15000         5375             5350       121.45          -1\n",
       "3     C            0.2          1               1           RENT  10.08  debt_consolidation           12.21520            0                 1               1                 1                      1         4        0             1        91.7                 0.0     13.49         570.26       30000         9000             9000       305.38          -1\n",
       "4     B            0.4          0               4           RENT   7.06               other            3.90888            0                 1               2                 1                      1        14        0             1        55.5                 0.0     10.65        1393.42      100000        10000            10000       325.74          -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies \n",
    "            'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]\n",
    "\n",
    "# Extract the feature columns and target column\n",
    "loans_data = loans_data[features + [target]]\n",
    "\n",
    "loans_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Pre-processing on Categorical Features (You saw it in the last assignment)\n",
    "#### cr. Henry Wong\n",
    "* Due to a quirk in Sklearn's Decision Tree implementation, Scikit-Learn is only able to accept categorical features. \n",
    "* Therefore we will encode the categorical features in our dataset with onehot encoding using pandas' `get_dummies()` function. \n",
    "* Thus we will also need to modify our features list accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>purpose_car</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>435.17</td>\n",
       "      <td>30000</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>59.83</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.55</td>\n",
       "      <td>4.57170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.28</td>\n",
       "      <td>294.94</td>\n",
       "      <td>40000</td>\n",
       "      <td>5600</td>\n",
       "      <td>5600</td>\n",
       "      <td>152.39</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.08</td>\n",
       "      <td>9.71600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.69</td>\n",
       "      <td>533.42</td>\n",
       "      <td>15000</td>\n",
       "      <td>5375</td>\n",
       "      <td>5350</td>\n",
       "      <td>121.45</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.08</td>\n",
       "      <td>12.21520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.49</td>\n",
       "      <td>570.26</td>\n",
       "      <td>30000</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>305.38</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.06</td>\n",
       "      <td>3.90888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>1393.42</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>325.74</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub_grade_num  short_emp  emp_length_num    dti  payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  last_major_derog_none  open_acc  pub_rec  pub_rec_zero  revol_util  total_rec_late_fee  int_rate  total_rec_int  annual_inc  funded_amnt  funded_amnt_inv  installment  safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  home_ownership_MORTGAGE  home_ownership_OTHER  home_ownership_OWN  home_ownership_RENT  purpose_car  purpose_credit_card  purpose_debt_consolidation  purpose_home_improvement  purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  purpose_small_business  purpose_vacation  purpose_wedding\n",
       "0            0.8          1               1   1.00            2.39320            0                 1               5                 1                      1         3        0             1         9.4                 0.0     15.27         435.17       30000         2500             2500        59.83          -1        0        0        1        0        0        0        0                        0                     0                   0                    1            1                    0                           0                         0              0                       0                0               0              0                       0                 0                0\n",
       "1            0.4          0               5   5.55            4.57170            0                 1               2                 1                      1        11        0             1        32.6                 0.0     21.28         294.94       40000         5600             5600       152.39          -1        0        0        0        0        0        1        0                        0                     0                   1                    0            0                    0                           0                         0              0                       0                0               0              0                       1                 0                0\n",
       "2            1.0          1               1  18.08            9.71600            0                 1               0                 1                      1         2        0             1        36.5                 0.0     12.69         533.42       15000         5375             5350       121.45          -1        0        1        0        0        0        0        0                        0                     0                   0                    1            0                    0                           0                         0              0                       0                0               0              1                       0                 0                0\n",
       "3            0.2          1               1  10.08           12.21520            0                 1               1                 1                      1         4        0             1        91.7                 0.0     13.49         570.26       30000         9000             9000       305.38          -1        0        0        1        0        0        0        0                        0                     0                   0                    1            0                    0                           1                         0              0                       0                0               0              0                       0                 0                0\n",
       "4            0.4          0               4   7.06            3.90888            0                 1               2                 1                      1        14        0             1        55.5                 0.0     10.65        1393.42      100000        10000            10000       325.74          -1        0        1        0        0        0        0        0                        0                     0                   0                    1            0                    0                           0                         0              0                       0                0               0              1                       0                 0                0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_data = pd.get_dummies(loans_data)\n",
    "loans_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub_grade_num',\n",
       " 'short_emp',\n",
       " 'emp_length_num',\n",
       " 'dti',\n",
       " 'payment_inc_ratio',\n",
       " 'delinq_2yrs',\n",
       " 'delinq_2yrs_zero',\n",
       " 'inq_last_6mths',\n",
       " 'last_delinq_none',\n",
       " 'last_major_derog_none',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'pub_rec_zero',\n",
       " 'revol_util',\n",
       " 'total_rec_late_fee',\n",
       " 'int_rate',\n",
       " 'total_rec_int',\n",
       " 'annual_inc',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'installment',\n",
       " 'grade_A',\n",
       " 'grade_B',\n",
       " 'grade_C',\n",
       " 'grade_D',\n",
       " 'grade_E',\n",
       " 'grade_F',\n",
       " 'grade_G',\n",
       " 'home_ownership_MORTGAGE',\n",
       " 'home_ownership_OTHER',\n",
       " 'home_ownership_OWN',\n",
       " 'home_ownership_RENT',\n",
       " 'purpose_car',\n",
       " 'purpose_credit_card',\n",
       " 'purpose_debt_consolidation',\n",
       " 'purpose_home_improvement',\n",
       " 'purpose_house',\n",
       " 'purpose_major_purchase',\n",
       " 'purpose_medical',\n",
       " 'purpose_moving',\n",
       " 'purpose_other',\n",
       " 'purpose_small_business',\n",
       " 'purpose_vacation',\n",
       " 'purpose_wedding']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(loans_data.columns)\n",
    "features.remove(target)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains now is a subset of features and the target that we will use for the rest of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hey, you look nice today ðŸ˜†    \n",
    "    * Seriously, if you aren't doing this super last minute...the weather is great outside!\n",
    "* We split the data into training data and validation data. \n",
    "* Let's use `random_state=1` to make sure everyone gets the same results! \n",
    "* We will use the validation data to help us select model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, validation_data = train_test_split(loans_data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's take a look at how many data in each set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37202, 45)\n",
      "(9301, 45)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this mean?\n",
    "* You should have 37202 data in the training set, and 9301 data in the test set.\n",
    "* Each with 45 columns, each column is a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboosted tree classifier\n",
    "\n",
    "Adaboosted trees are a powerful variant of boosting methods; they have been used to win many [Kaggle](https://www.kaggle.com/) competitions, and have been widely used in industry.  We will explore the predictive power of multiple decision trees as opposed to a single decision tree.\n",
    "\n",
    ">**Resources:** If you are interested in adaboosted trees, here is some useful additional reading material:\n",
    "* [Doc: sk.ensemble.AdaBoostClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
    "* [Optional Reading: Advanced Material on Boosted Trees Slide](http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)\n",
    "* [Demo: Two Class Adaboost](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_twoclass.html)\n",
    "* [Demo: Feature Transformation with Ensembles of Trees (For advanced humans)](https://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py)\n",
    "\n",
    "\n",
    "* We will now train models to predict `safe_loans` using the features above.\n",
    "\n",
    "### Making the model\n",
    "* Train an AdaBoostClassifier model with 5 DecisionTreeClassifiers, each with depth 7. Save the model to `model_5`.\n",
    "\n",
    "* Use `train_data` to fit the model. `features` contains the list of input features, and `target` is what we are trying to predict.\n",
    "\n",
    "* Set `random_state=1` when constructing both the DecisionTreeClassifier and AdaBoostClassifier, so that we get the same results\n",
    "\n",
    "* More details:\n",
    "    * Remember when we talked in last homework, the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) uses the `max_depth` parameter to control the depth of the tree?\n",
    "    * AdaBoostClassifier is essentially using many trees, so when you call AdaBoostClassifier, it is actually calling `DecisionTreeClassifier(max_depth=someNumberOfDepth)` from the inside to create a AdaBoostClassifier model. We use a parameter called `n_estimators` to determine how many trees to use when constructing the AdaBoostClassifier.\n",
    "    * Note: Because we are using a small number of trees, we need to make the trees a bit deeper to achieve optimum result. Namely, instead of each tree has depth of `5`, we let it to have depth`7` to make it a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=5, random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here!\n",
    "model_5 = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 7, random_state=1), n_estimators = 5, random_state = 1)\n",
    "model_5.fit(train_data[features], train_data[target])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating the model on the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the accuracy is defined as follows:\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Evaluate the accuracy of the **model_5** on the **validation_data**.\n",
    "\n",
    "**Hint**: Use the `accuracy_score` that we used in the last assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statement\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628319535533813"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here!\n",
    "accuracy_score(validation_data[target], model_5.predict(validation_data[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of **false positives** made by the model on the validation set.\n",
    "\n",
    "If you are trying to loop through the true target values index by index, note that `validation_data[target]` is a **data frame**. So to access the i-th row, you'll need to do `validation_data[target].iloc[i]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "\n",
    "fp = 0\n",
    "pred = model_5.predict(validation_data[features])\n",
    "true = validation_data[target]\n",
    "for i in range(len(true)):\n",
    "    if pred[i] == 1 and true.iloc[i] == -1:\n",
    "        fp += 1\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q1**: What is the number of **false positives** on the **validation_data**? 1636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of **false negatives** made by the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "fn = 0\n",
    "for i in range(len(true)):\n",
    "    if pred[i] == -1 and true.iloc[i] == 1:\n",
    "        fn += 1\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q2**: What is the number of **false negatives** on the **validation_data**? 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with decision trees\n",
    "* Let's see what if we just use a simple decision tree instead.\n",
    "    * Using a simple decision tree, the validation accuracy is: 0.6569186109020535.\n",
    "    * Since calculating this would be repeated work, we calculated it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we quantify the benefit of the extra increase in accuracy of **model_5** in comparison with a single decision tree from the original decision tree assignment.\n",
    "\n",
    "As we explored in the earlier assignment, we calculated the cost of the mistakes made by the model. We again consider the same costs as follows:\n",
    "\n",
    "* **False negatives**: Assume a cost of \\$10,000 per false negative.\n",
    "* **False positives**: Assume a cost of \\$20,000 per false positive.\n",
    "\n",
    "Assume that the number of false positives and false negatives for the learned decision tree was\n",
    "\n",
    "* **False negatives**: 1552\n",
    "* **False positives**: 1639\n",
    "\n",
    "Using the costs defined above and the number of false positives and false negatives for the decision tree, we can calculate the total cost of the mistakes made by the decision tree model as follows:\n",
    "\n",
    "```\n",
    "cost = $10,000 * 1552  + $20,000 * 1639 = $48300000\n",
    "```\n",
    "\n",
    "The total cost of the mistakes of the model is $48.3M. That is a **lot of money**!.\n",
    "\n",
    "### **Q3**: Using the same costs of the false positives and false negatives, what is the cost of the mistakes made by the boosted tree model (**model_5**) as evaluated on the **validation_set**? 47720000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47720000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here!\n",
    "10000*fn + 20000*fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**: Compare the cost of the mistakes made by the boosted trees model with the decision tree model. The extra improvement in prediction accuracy can translate to several million dollars!  And, it was so easy to get by simply boosting our decision trees.ðŸ¤‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most positive & negative loans.\n",
    "\n",
    "In this section, we will find the loans that are most likely to be predicted **safe**. We can do this in a few steps:\n",
    "\n",
    "* **Step 1**: Use the **model_5** (the model with 5 trees) and make **probability predictions** for all the loans in the **validation_data**.\n",
    "* **Step 2**: Similar to what we did in the very first assignment, add the probability predictions as a column called **predictions** into the validation_data.\n",
    "* **Step 3**: Sort the data (in descreasing order) by the probability predictions.\n",
    "\n",
    "Start here with **Step 1** & **Step 2**. Make predictions using **model_5** for examples in the **validation_data**. \n",
    "#### Hint:\n",
    "* There is a method in the [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) that can predict class probabilities of a certain input.\n",
    "* That method returns a probability of +1 and a probability of -1, make sure you are using the right one.(!!!)\n",
    "* Note: the method will return a 2-D list. Each sub-list contains two entries; first is the probability of -1, and second is the probability of +1. To extract the second column (with the probabilities of +1), you can do `[:,1]` to the end of the 2-D list.\n",
    "* [How to extract a column from a n-D array?](https://stackoverflow.com/questions/903853/how-do-you-extract-a-column-from-a-multi-dimensional-array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "predictions = model_5.predict_proba(validation_data[features])\n",
    "validation_data['predictions'] = predictions[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For each row, the probabilities should be a number in the range **[0, 1]**. We have provided a simple check here to make sure your answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loans      : [0.5572405466863586, 0.5134051586799435, 0.47499886376920475, 0.5645160637619324]\n",
      "\n",
      "Expected answer : [0.5572405466863586, 0.5134051586799435, 0.47499886376920475, 0.5645160637619324]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your loans      : %s\\n\" % list(validation_data['predictions'].head(4)))\n",
    "print(\"Expected answer : %s\" % [0.5572405466863586, 0.5134051586799435,\n",
    "                                0.47499886376920475, 0.5645160637619324])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to go to **Step 3**. You can now use the `predictions` column to sort the loans in **validation_data** (in descending order) by prediction probability. Find the top 5 loans with the highest probability of being predicted as a **safe loan**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>purpose_car</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39608</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.961132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1035.11</td>\n",
       "      <td>456000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>365.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15648</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.77</td>\n",
       "      <td>3.652300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>18.26</td>\n",
       "      <td>6.03</td>\n",
       "      <td>905.49</td>\n",
       "      <td>120000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>365.23</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39687</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.542080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.03</td>\n",
       "      <td>94.62</td>\n",
       "      <td>225000</td>\n",
       "      <td>9500</td>\n",
       "      <td>9500</td>\n",
       "      <td>289.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26559</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.723430</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.42</td>\n",
       "      <td>428.41</td>\n",
       "      <td>105000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>150.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45831</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.69</td>\n",
       "      <td>3.371350</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.03</td>\n",
       "      <td>634.56</td>\n",
       "      <td>130000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>365.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub_grade_num  short_emp  emp_length_num   dti  payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  last_major_derog_none  open_acc  pub_rec  pub_rec_zero  revol_util  total_rec_late_fee  int_rate  total_rec_int  annual_inc  funded_amnt  funded_amnt_inv  installment  safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  home_ownership_MORTGAGE  home_ownership_OTHER  home_ownership_OWN  home_ownership_RENT  purpose_car  purpose_credit_card  purpose_debt_consolidation  purpose_home_improvement  purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  purpose_small_business  purpose_vacation  purpose_wedding  predictions\n",
       "39608            0.2          0               4  0.16           0.961132            0                 1               0                 1                      1         5        0             1        11.9                0.00      6.03        1035.11      456000        12000            12000       365.23           1        1        0        0        0        0        0        0                        0                     0                   0                    1            0                    0                           0                         0              0                       0                0               0              0                       1                 0                0     1.000000\n",
       "15648            0.2          0               4  7.77           3.652300            0                 1               0                 1                      1         6        0             1         6.1               18.26      6.03         905.49      120000        12000            12000       365.23          -1        1        0        0        0        0        0        0                        0                     0                   0                    1            0                    0                           1                         0              0                       0                0               0              0                       0                 0                0     1.000000\n",
       "39687            0.2          0              10  4.80           1.542080            0                 1               0                 1                      1         9        0             1         4.5                0.00      6.03          94.62      225000         9500             9500       289.14           1        1        0        0        0        0        0        0                        1                     0                   0                    0            0                    0                           0                         0              0                       0                0               0              0                       0                 1                0     0.999963\n",
       "26559            0.2          0               3  5.14           1.723430            0                 1               1                 1                      1         7        0             1         8.5                0.00      5.42         428.41      105000         5000             5000       150.80           1        1        0        0        0        0        0        0                        1                     0                   0                    0            1                    0                           0                         0              0                       0                0               0              0                       0                 0                0     0.999575\n",
       "45831            0.2          1               1  6.69           3.371350            0                 1               1                 1                      1         8        0             1         5.2                0.00      6.03         634.56      130000        12000            12000       365.23           1        1        0        0        0        0        0        0                        1                     0                   0                    0            0                    0                           0                         1              0                       0                0               0              0                       0                 0                0     0.999574"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here!\n",
    "validation_data.nlargest(5, 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q4**: What grades are the top 5 loans?\n",
    "\n",
    "Hint: remember that the `grade` feature was one-hot encoded. For example, the `grade_A` column is 1 if the loan was grade A, and 0 otherwise.\n",
    "- ABACB\n",
    "- BBBAA\n",
    "- BACAA\n",
    "- AAAAA (o)\n",
    "- BBCBA\n",
    "\n",
    "Let us repeat this excercise to find the top 5 loans (in the **validation_data**) with the **lowest probability** of being predicted as a **safe loan**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_OTHER</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>purpose_car</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.99743</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>104.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.067802e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.45</td>\n",
       "      <td>13.45090</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76000</td>\n",
       "      <td>25000</td>\n",
       "      <td>11625</td>\n",
       "      <td>851.89</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.342747e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.95203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250000</td>\n",
       "      <td>24000</td>\n",
       "      <td>23075</td>\n",
       "      <td>823.34</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.502721e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>4.82151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19968</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>80.23</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.678670e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.42</td>\n",
       "      <td>8.43097</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>1039.82</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.096260e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sub_grade_num  short_emp  emp_length_num   dti  payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  last_major_derog_none  open_acc  pub_rec  pub_rec_zero  revol_util  total_rec_late_fee  int_rate  total_rec_int  annual_inc  funded_amnt  funded_amnt_inv  installment  safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  home_ownership_MORTGAGE  home_ownership_OTHER  home_ownership_OWN  home_ownership_RENT  purpose_car  purpose_credit_card  purpose_debt_consolidation  purpose_home_improvement  purpose_house  purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  purpose_small_business  purpose_vacation  purpose_wedding   predictions\n",
       "1636             0.2          0               5  1.49            2.99743            3                 0               0                 0                      1         5        0             1        13.4                 0.0     15.62            0.0       42000         3000             3000       104.91          -1        0        0        0        1        0        0        0                        0                     0                   0                    1            0                    0                           0                         0              0                       0                0               0              0                       1                 0                0  5.067802e-09\n",
       "4901             1.0          0               2  4.45           13.45090            0                 1               2                 0                      1        13        0             1         2.5                 0.0     13.79            0.0       76000        25000            11625       851.89          -1        0        0        1        0        0        0        0                        1                     0                   0                    0            0                    0                           0                         1              0                       0                0               0              0                       0                 0                0  5.342747e-09\n",
       "5608             1.0          0               2  3.62            3.95203            0                 1               5                 1                      1         4        0             1        83.9                 0.0     14.26            0.0      250000        24000            23075       823.34          -1        0        0        1        0        0        0        0                        0                     0                   0                    1            0                    0                           0                         1              0                       0                0               0              0                       0                 0                0  5.502721e-09\n",
       "3142             0.6          0               2  2.94            4.82151            0                 1               3                 1                      1         4        0             1        38.1                 0.0      9.62            0.0       19968         2500             2500        80.23          -1        0        1        0        0        0        0        0                        0                     0                   0                    1            0                    0                           1                         0              0                       0                0               0              0                       0                 0                0  6.678670e-09\n",
       "20988            1.0          0               9  4.42            8.43097            1                 0               0                 0                      1         8        0             1        44.4                 0.0     14.99            0.0      148000        30000            30000      1039.82          -1        0        0        1        0        0        0        0                        1                     0                   0                    0            0                    0                           0                         1              0                       0                0               0              0                       0                 0                0  1.096260e-08"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here!\n",
    "validation_data.nsmallest(5, 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** What grades are the bottom 5 loans?\n",
    "- FCBFE\n",
    "- DCCBC (o)\n",
    "- FFCED\n",
    "- DDBDD\n",
    "- FCFFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of adding more trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will train several different ensemble classifiers in the form of gradient boosted trees. We will train models with 10, 15, 20, 50, 100, 200, and 500 trees.  We use the **max_iterations** parameter in the boosted tree module. \n",
    "\n",
    "* Fill in the code below to populate the `models` list with models using the given numbers of trees.\n",
    "    * In this models, we will let the depth of each tree to be `3` instead of `7` in the previous section, so we can observe the effect of adding many many many small trees.\n",
    "    * Again, set `random_state=1` every time you create an AdaBoostClassifier and DecisionTreeClassifier.\n",
    "* **Warning:** This could take a while to run, so don't panic! We are training a model with 500 trees.\n",
    "    * I got a pretty little status bar for you! So you don't need to write ugly print statements!\n",
    "    * [How to display a progress bar in notebook?](https://mikulskibartosz.name/how-to-display-a-progress-bar-in-jupyter-notebook-47bd4c2944bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status Bar\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "models = []\n",
    "tree_counts = [10,15,20,50,100,200,500]\n",
    "progress = 0\n",
    "all_iterations = sum(tree_counts)\n",
    "\n",
    "\n",
    "for x in tree_counts:\n",
    "    print('Currently training model tree size:',x)  # Progress Bar\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 3, random_state=1), n_estimators = x, random_state = 1)\n",
    "    model.fit(train_data[features], train_data[target])\n",
    "    models.append(model)\n",
    "\n",
    "    progress += x  # Progress Bar\n",
    "    update_progress(progress / all_iterations)  # Progress Bar\n",
    "    \n",
    "update_progress(1)  # Progress Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracy on entire validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compare the predicitve accuracy of our models on the validation set. Evaluate the **accuracy** of the 10, 15, 20, 50, 100, 200, and 500 tree models on the **validation_data**. Use the `accuracy_score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6640146220836469, 0.6632620148371143, 0.665412321255779, 0.6716482098699065, 0.669605418772175, 0.6646597140092463, 0.6520804214600581]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "accs = list()\n",
    "for m in models:\n",
    "    acc = accuracy_score(validation_data[target], m.predict(validation_data[features]))\n",
    "    accs.append(acc)\n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:** Which model has the **best** accuracy on the **validation_data**?\n",
    "- 10 tree\n",
    "- 15 tree\n",
    "- 50 tree (o)\n",
    "- 100 tree\n",
    "- 200 tree\n",
    "- 500 tree\n",
    "\n",
    "**Q7:** Is it always true that the model with the most trees will perform best on test data?\n",
    "- yes\n",
    "- no (o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and validation error vs. number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the lecture that the classification error is defined as\n",
    "\n",
    "$$\n",
    "\\mbox{classification error} = 1 - \\mbox{accuracy} \n",
    "$$\n",
    "\n",
    "In this section, we will plot the **training and validation errors versus the number of trees** to get a sense of how these models are performing. We will compare the 10, 15, 20, 50, 100, 200, and 500 tree models. We will use [matplotlib](https://matplotlib.org/index.html) in order to visualize the plots. \n",
    "\n",
    "First, run the following method to use as graphing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the classification errors (on the **train_data** and **validation_data**) versus the number of trees, we will need lists of these accuracies, which we get by applying the method `accuracy_score()`. \n",
    "\n",
    "Let us start with **Step 1**. Write code to compute the classification error on the **train_data** for models with 10, 15, 20, 50, 100, 200, and 500 trees, and store these errors in a list `training_errors`.\n",
    "\n",
    "Note that the classification error is just 1 minus the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "training_errors = []\n",
    "for m in models:\n",
    "    err = 1-accuracy_score(train_data[target], m.predict(train_data[features]))\n",
    "    training_errors.append(err)\n",
    "print(len(training_errors))\n",
    "print(len(tree_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, onto **Step 2**. Write code to compute the classification error on the **validation_data** for models 10, 15, 20, 50, 100, 200, and 500 trees, saving this into a different list `validation_errors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "## Write your code here!\n",
    "validation_errors = []\n",
    "for m in models:\n",
    "    err = 1-accuracy_score(validation_data[target], m.predict(validation_data[features]))\n",
    "    validation_errors.append(err)\n",
    "print(len(validation_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will plot the `training_errors` and `validation_errors` versus the number of trees. We will compare the 10, 15, 20, 50, 100, 200, and 500 tree models. We provide some plotting code to visualize the plots within this notebook. \n",
    "\n",
    "Run the following code to visualize the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tree_counts, training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot(tree_counts, validation_errors, linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8**: According to the graph, does the training error reduce as the number of trees increases?\n",
    "- Yes (o)\n",
    "- No\n",
    "- Yes and No (Depends)\n",
    "\n",
    "**Q9**: Is it always true that the validation error will reduce as the number of trees increases?\n",
    "- Yes\n",
    "- No (o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, it looks like you are really an intellegent boosted human to reach this point.\n",
    "### Oh yeah, there is another notebook you need to do, just so you know.\n",
    "* It's like Erwin SchrÃ¶dinger's CSE 416 Homework 5.\n",
    "    * When I am writing this assignment 4 AM in the morning, you are at a state that you both completed and did not complete all the assignment.\n",
    "    * Now, you can observe yourself and make sure you are in a state that you completed all of Assignment 5. \n",
    "    * If not, there is a document retrieval part of Assignment 5 which you can learn all about studying a group of famous and powerful american humans!\n",
    "    * (Nope, not the super heroes, sorry)\n",
    "    \n",
    "### Don't forget to make sure you submitted your quiz AND your notebook!  \n",
    "### You might want to post to this [really cool online discussion board](https://canvas.uw.edu/courses/1271722/discussion_topics) too.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
